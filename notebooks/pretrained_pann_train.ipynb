{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827b44bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jaeheonshim/music-vibes\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jaeheonshim/music-vibes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "118f98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, autocast\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import random_split, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import defaultdict\n",
    "\n",
    "from vibenet import labels\n",
    "from vibenet.dataset import FMAWaveformDataset\n",
    "from vibenet.models.teacher import PANNsMLP\n",
    "from vibenet.train_utils import compute_losses, compute_metrics\n",
    "\n",
    "device = 'cuda'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a1345",
   "metadata": {},
   "source": [
    "Acousticness, Instrumentalness, and Liveness are **likelihoods** (e.g. a track having a 1.0 acousticness represents a high *confidence* that the track is acoustic). Thus, we use binary cross-entropy loss to optimize them.\n",
    "\n",
    "Speechiness, Danceability, Energy, and Valence are **perceptual measures** (e.g. a danceability value of 0.0.0 is least danceable and 1.0 is most danceable). We use Huber and MSE loss to optimize Speechiness and Danceability, and concordance correlation coefficient (CCC) to optimize energy and valence (https://arxiv.org/abs/2003.10724)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4dd78",
   "metadata": {},
   "source": [
    "### Load the dataset and perform train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3880cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FMAWaveformDataset('data/preprocessed/waveforms_train')\n",
    "test_ds = FMAWaveformDataset('data/preprocessed/waveforms_val')\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a2906",
   "metadata": {},
   "source": [
    "### Initialize model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771723bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional helper functions for training last layer of PANN Cnn14\n",
    "def set_bn_eval(m):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "\n",
    "def trainable_params(module):\n",
    "    return [p for p in module.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8883301c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PANNsMLP()\n",
    "model = model.to(device)\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "pg_backbone6 = trainable_params(model.pann.conv_block6)\n",
    "pg_heads = trainable_params(model.trunk) + trainable_params(model.heads)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": pg_backbone6, \"lr\": 1e-5, \"weight_decay\": 1e-4},\n",
    "    {\"params\": pg_heads, \"lr\": 1e-3, \"weight_decay\": 5e-4},\n",
    "])\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6716e4c",
   "metadata": {},
   "source": [
    "### Train/Validate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b5051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "def train():\n",
    "    global global_step\n",
    "    \n",
    "    model.apply(set_bn_eval)\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "\n",
    "    with tqdm(train_dl, desc='Training') as pbar:\n",
    "        for data, label in pbar:\n",
    "            data, label = data.to(device).float(), label.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                pred = model(data)\n",
    "                \n",
    "                loss_total = 0.0\n",
    "                losses = compute_losses(pred, label)\n",
    "                for k, l in losses.items():\n",
    "                    writer.add_scalar(f\"train/loss/{k}\", l, global_step)\n",
    "                    loss_total += l\n",
    "                \n",
    "            scaler.scale(loss_total).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_losses.append(loss_total.item())\n",
    "            \n",
    "            mean_loss = np.mean(train_losses)\n",
    "            writer.add_scalar(f\"train/loss\", mean_loss, global_step)\n",
    "            pbar.set_postfix({'loss': f\"{mean_loss:.4f}\"})\n",
    "            \n",
    "            global_step += 1\n",
    "\n",
    "def validate():\n",
    "    global global_step\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    preds = defaultdict(list)\n",
    "    targets = []\n",
    "\n",
    "    with tqdm(test_dl, desc='Validation') as pbar:\n",
    "        with torch.inference_mode():\n",
    "            for data, label in pbar:\n",
    "                data, label = data.to(device).float(), label.to(device).float()\n",
    "\n",
    "                pred = model(data)\n",
    "                for l, p in pred.items():\n",
    "                    preds[l].append(p.detach().cpu())\n",
    "\n",
    "                targets.append(label.detach().cpu())\n",
    "\n",
    "    preds = {k: torch.cat(preds[k], dim=0) for k in preds.keys()}\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "\n",
    "    losses = compute_losses(preds, targets)\n",
    "    loss_total = 0.0\n",
    "            \n",
    "    for k,l in losses.items():\n",
    "        loss_total += l\n",
    "        \n",
    "    writer.add_scalar(f\"eval/loss\", loss_total, global_step)\n",
    "    \n",
    "    metrics = compute_metrics(preds, targets)\n",
    "\n",
    "    return metrics, loss_total.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7096d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Training:  69%|███████████████████████████████████████████████████████████████████████████████████████▌                                       | 870/1261 [29:34<08:59,  1.38s/it, loss=1.9525]Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:37<00:00,  2.03s/it, loss=1.9502]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:43<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                      | 0/1261 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|████▊                                                                                                                           | 48/1261 [01:39<16:14,  1.24it/s, loss=2.7747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9666\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4856\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0162\n",
      "  rmse    : 0.1272\n",
      "  mae     : 0.1005\n",
      "  pearson : 0.7505\n",
      "  ccc     : 0.7418\n",
      "  r2      : 0.5503\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0266\n",
      "  rmse    : 0.1631\n",
      "  mae     : 0.1224\n",
      "  pearson : 0.8482\n",
      "  ccc     : 0.8432\n",
      "  r2      : 0.6534\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5079\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4757\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0104\n",
      "  rmse    : 0.1019\n",
      "  mae     : 0.0492\n",
      "  pearson : 0.7346\n",
      "  ccc     : 0.7322\n",
      "  r2      : 0.4923\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0505\n",
      "  rmse    : 0.2247\n",
      "  mae     : 0.1704\n",
      "  pearson : 0.6995\n",
      "  ccc     : 0.6956\n",
      "  r2      : 0.3194\n",
      "\n",
      "Epoch 20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:41<00:00,  2.03s/it, loss=1.9413]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:43<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9701\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4817\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0166\n",
      "  rmse    : 0.1288\n",
      "  mae     : 0.1017\n",
      "  pearson : 0.7462\n",
      "  ccc     : 0.7400\n",
      "  r2      : 0.5391\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0290\n",
      "  rmse    : 0.1704\n",
      "  mae     : 0.1298\n",
      "  pearson : 0.8493\n",
      "  ccc     : 0.8375\n",
      "  r2      : 0.6214\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5088\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4758\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0104\n",
      "  rmse    : 0.1019\n",
      "  mae     : 0.0482\n",
      "  pearson : 0.7335\n",
      "  ccc     : 0.7306\n",
      "  r2      : 0.4927\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0519\n",
      "  rmse    : 0.2279\n",
      "  mae     : 0.1719\n",
      "  pearson : 0.7014\n",
      "  ccc     : 0.6951\n",
      "  r2      : 0.2997\n",
      "\n",
      "Epoch 21:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:41<00:00,  2.03s/it, loss=1.9337]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:43<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9645\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4818\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0165\n",
      "  rmse    : 0.1284\n",
      "  mae     : 0.1013\n",
      "  pearson : 0.7503\n",
      "  ccc     : 0.7457\n",
      "  r2      : 0.5419\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0284\n",
      "  rmse    : 0.1685\n",
      "  mae     : 0.1278\n",
      "  pearson : 0.8486\n",
      "  ccc     : 0.8391\n",
      "  r2      : 0.6299\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5069\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4757\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0105\n",
      "  rmse    : 0.1026\n",
      "  mae     : 0.0493\n",
      "  pearson : 0.7307\n",
      "  ccc     : 0.7293\n",
      "  r2      : 0.4849\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0514\n",
      "  rmse    : 0.2267\n",
      "  mae     : 0.1718\n",
      "  pearson : 0.7036\n",
      "  ccc     : 0.6972\n",
      "  r2      : 0.3071\n",
      "Saved new best model\n",
      "\n",
      "Epoch 22:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:40<00:00,  2.03s/it, loss=1.9259]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:43<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9641\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4807\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0162\n",
      "  rmse    : 0.1273\n",
      "  mae     : 0.1004\n",
      "  pearson : 0.7523\n",
      "  ccc     : 0.7458\n",
      "  r2      : 0.5501\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0273\n",
      "  rmse    : 0.1652\n",
      "  mae     : 0.1245\n",
      "  pearson : 0.8480\n",
      "  ccc     : 0.8419\n",
      "  r2      : 0.6443\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5078\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4755\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0105\n",
      "  rmse    : 0.1026\n",
      "  mae     : 0.0491\n",
      "  pearson : 0.7319\n",
      "  ccc     : 0.7306\n",
      "  r2      : 0.4848\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0521\n",
      "  rmse    : 0.2283\n",
      "  mae     : 0.1711\n",
      "  pearson : 0.7015\n",
      "  ccc     : 0.6941\n",
      "  r2      : 0.2972\n",
      "Saved new best model\n",
      "\n",
      "Epoch 23:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:39<00:00,  2.03s/it, loss=1.9169]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:43<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9599\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4784\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0161\n",
      "  rmse    : 0.1271\n",
      "  mae     : 0.1003\n",
      "  pearson : 0.7520\n",
      "  ccc     : 0.7445\n",
      "  r2      : 0.5515\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0276\n",
      "  rmse    : 0.1661\n",
      "  mae     : 0.1250\n",
      "  pearson : 0.8491\n",
      "  ccc     : 0.8408\n",
      "  r2      : 0.6403\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5061\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4756\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0108\n",
      "  rmse    : 0.1038\n",
      "  mae     : 0.0493\n",
      "  pearson : 0.7326\n",
      "  ccc     : 0.7321\n",
      "  r2      : 0.4731\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0514\n",
      "  rmse    : 0.2267\n",
      "  mae     : 0.1703\n",
      "  pearson : 0.7013\n",
      "  ccc     : 0.6958\n",
      "  r2      : 0.3071\n",
      "Saved new best model\n",
      "\n",
      "Epoch 24:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:41<00:00,  2.03s/it, loss=1.9113]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:44<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9628\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4817\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0162\n",
      "  rmse    : 0.1273\n",
      "  mae     : 0.1006\n",
      "  pearson : 0.7508\n",
      "  ccc     : 0.7431\n",
      "  r2      : 0.5500\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0276\n",
      "  rmse    : 0.1660\n",
      "  mae     : 0.1251\n",
      "  pearson : 0.8491\n",
      "  ccc     : 0.8420\n",
      "  r2      : 0.6408\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5066\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4754\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0106\n",
      "  rmse    : 0.1028\n",
      "  mae     : 0.0493\n",
      "  pearson : 0.7357\n",
      "  ccc     : 0.7352\n",
      "  r2      : 0.4832\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0518\n",
      "  rmse    : 0.2275\n",
      "  mae     : 0.1703\n",
      "  pearson : 0.7009\n",
      "  ccc     : 0.6952\n",
      "  r2      : 0.3020\n",
      "\n",
      "Epoch 25:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1261/1261 [42:40<00:00,  2.03s/it, loss=1.9021]\n",
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 451/451 [02:44<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9593\n",
      "\n",
      "[acousticness]\n",
      "  logloss : 0.4792\n",
      "\n",
      "[danceability]\n",
      "  mse     : 0.0164\n",
      "  rmse    : 0.1279\n",
      "  mae     : 0.1009\n",
      "  pearson : 0.7502\n",
      "  ccc     : 0.7430\n",
      "  r2      : 0.5457\n",
      "\n",
      "[energy]\n",
      "  mse     : 0.0275\n",
      "  rmse    : 0.1657\n",
      "  mae     : 0.1249\n",
      "  pearson : 0.8506\n",
      "  ccc     : 0.8430\n",
      "  r2      : 0.6419\n",
      "\n",
      "[instrumentalness]\n",
      "  logloss : 0.5066\n",
      "\n",
      "[liveness]\n",
      "  logloss : 0.4755\n",
      "\n",
      "[speechiness]\n",
      "  mse     : 0.0108\n",
      "  rmse    : 0.1042\n",
      "  mae     : 0.0495\n",
      "  pearson : 0.7332\n",
      "  ccc     : 0.7330\n",
      "  r2      : 0.4695\n",
      "\n",
      "[valence]\n",
      "  mse     : 0.0516\n",
      "  rmse    : 0.2271\n",
      "  mae     : 0.1697\n",
      "  pearson : 0.7028\n",
      "  ccc     : 0.6959\n",
      "  r2      : 0.3044\n",
      "Saved new best model\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}:\")\n",
    "    \n",
    "    writer.add_scalar(f\"epoch\", epoch, global_step)\n",
    "\n",
    "    train()\n",
    "    metrics, loss_total = validate()\n",
    "\n",
    "    print(f\"Loss: {loss_total:.4f}\")\n",
    "    for task, stats in metrics.items():\n",
    "        print(f\"\\n[{task}]\")\n",
    "        max_name_len = max(len(k) for k in stats.keys())\n",
    "        for name, val in stats.items():\n",
    "            writer.add_scalar(f\"eval/{task}/{name}\", val, global_step)\n",
    "            \n",
    "            if isinstance(val, float):\n",
    "                print(f\"  {name:<{max_name_len}} : {val:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {name:<{max_name_len}} : {val}\")\n",
    "\n",
    "    if loss_total < best_loss:\n",
    "        best_loss = loss_total\n",
    "        torch.save({'state_dict': model.state_dict()},\n",
    "                   'checkpoints/pretrained_PANN_best.pt')\n",
    "        print('Saved new best model')\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    global_step += 1\n",
    "    \n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a169989d",
   "metadata": {},
   "source": [
    "After 25 epochs, model achieved validation loss of 2.1312"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
